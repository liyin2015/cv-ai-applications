# Self-supervised Learning

SOTA paper:
* [Baevski, Alexei, et al. "Data2vec: A general framework for self-supervised learning in speech, vision and language." URL https://ai. facebook. com/research/data2veca-general-framework-for-self-supervi sed-learning-in-speech-vision-and-la nguage/. Accessed (2022): 01-27.](http://transformers.science/rct/articles/Baevski%20et%20al.-2022-data2vec%20A%20General%20Framework%20for%20Self-supervised%20Learning%20in%20Speech%2C%20Vision%20and%20Language.pdf). From this paper, we can find landmark papers for vision self-supervised learning. Data2vec predicts the latent representations of the
input data.
<hr>

## Vision
Here, we only focus on the vision self-supervised learning.
###  Landmark papers
* BYOL: [Grill, Jean-Bastien, et al. "Bootstrap your own latent-a new approach to self-supervised learning." Advances in Neural Information Processing Systems 33 (2020): 21271-21284.](https://proceedings.neurips.cc/paper/2020/file/f3ada80d5c4ee70142b17b8192b2958e-Paper.pdf). #cite: 1000
* DINO:[Caron, Mathilde, et al. "Emerging properties in self-supervised vision transformers." Proceedings of the IEEE/CVF International Conference on Computer Vision. 2021.](https://openaccess.thecvf.com/content/ICCV2021/papers/Caron_Emerging_Properties_in_Self-Supervised_Vision_Transformers_ICCV_2021_paper.pdf). #cite:300
* [He, Kaiming, et al. "Masked autoencoders are scalable vision learners." arXiv preprint arXiv:2111.06377 (2021).](https://arxiv.org/pdf/2111.06377.pdf?ref=https://githubhelp.com)

### Losses
* [SmoothL1Loss](https://pytorch.org/docs/stable/generated/torch.nn.SmoothL1Loss.html) -> data2vec
<hr>

## NLP
### Landmark papers
* BERT
* TinyBERT:[Jiao, X., Yin, Y., Shang, L., Jiang, X., Chen, X., Li, L., Wang, F., and Liu, Q. Tinybert: Distilling bert for natural language understanding. arXiv, abs/1909.10351, 2020.]()

<hr>

## Speech
* wav2vec 2.0
* HuBERT
